{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2e980-45c1-46bd-b40a-28471bb94a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.models import load_model\n",
    "import tensorflow\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "tensorflow.random.set_seed(20)\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40419687-4e01-4466-95ee-343a4dc4a49e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebcaeb-cfab-4ce6-b891-60c479b24d29",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343a10e-d5a2-4308-8ce3-31ca5d3960ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels=pd.read_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a77aa4-09de-4fde-ab2e-ba9bc47459dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Normalize data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "ss=MinMaxScaler()\n",
    "cols=['u', 'PCF', 'EA', 'SEA', 'k']\n",
    "tmp=pd.DataFrame(ss.fit_transform(labels[cols]),columns=cols)\n",
    "for col in cols:\n",
    "    labels[col]=tmp[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e709da-ee32-4894-bb69-2319fab4b88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b258eb-a64d-4973-a8d2-11f4922a232f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c966d8a-cddf-49a9-98b1-86f1361b8b07",
   "metadata": {},
   "source": [
    "## Create training and testing data â€“ same as Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93911a-e04f-4774-a1fb-2a6823c28e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32e649-1908-4e5f-b1e9-380222ba0765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "image_folder = \"./images\"\n",
    "train_folder = './train'\n",
    "test_folder = './test'\n",
    "\n",
    "# if os.path.exists(train_folder):\n",
    "#     shutil.rmtree(train_folder)\n",
    "# if os.path.exists(test_folder):\n",
    "#     shutil.rmtree(test_folder)\n",
    "# os.makedirs(train_folder, exist_ok=True)\n",
    "# os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# image_files = [i for i in os.listdir(image_folder) if i.find('jpg')>=0]\n",
    "# random.shuffle(image_files)\n",
    "\n",
    "\n",
    "# total_images = len(image_files)\n",
    "# train_images = int(total_images * 0.7)\n",
    "# test_images = total_images - train_images\n",
    "\n",
    "\n",
    "# for i, image_file in enumerate(image_files):\n",
    "#     source_path = os.path.join(image_folder, image_file)\n",
    "\n",
    "\n",
    "#     if i < train_images:\n",
    "#         destination_folder = train_folder\n",
    "#     else:\n",
    "#         destination_folder = test_folder\n",
    "\n",
    "\n",
    "#     destination_path = os.path.join(destination_folder, image_file)\n",
    "#     shutil.copyfile(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d7180-80fe-493b-8e58-1f17112fcb76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_list=[i for i in os.listdir(train_folder) if i.find('jpg')>=0]\n",
    "test_list=[i for i in os.listdir(test_folder) if i.find('jpg')>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59541da0-9918-4c1a-a138-41e1495ec86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv=labels[labels.name.isin(train_list)]\n",
    "test_csv=labels[labels.name.isin(test_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba723e-8c70-4cd0-82d3-b14f21007a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_list=['p','u', 'PCF', 'EA', 'SEA', 'k']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d68a8-d237-4045-b5ca-05555821b2d7",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f7c97-6dcd-41c2-9f9a-386f916c34ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "class CustomDataGenerator(Sequence):\n",
    "    def __init__(self, csv_file, directory, batch_size, target_size, label_list, shuffle=True, augment=False):\n",
    "        self.csv_file = csv_file\n",
    "        self.directory = directory\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.label_list = label_list\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        if self.augment:\n",
    "            self.image_data_generator = ImageDataGenerator(\n",
    "                rotation_range=20,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest')\n",
    "        else:\n",
    "            self.image_data_generator = ImageDataGenerator()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.csv_file) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.csv_file.iloc[k] for k in indexes]\n",
    "\n",
    "        X, y = self.__data_generation(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.csv_file))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, batch):\n",
    "        X1 = np.empty((self.batch_size, *self.target_size, 3))\n",
    "        X2 = np.empty((self.batch_size, 1))\n",
    "        y = np.empty((self.batch_size, len(self.label_list) - 1))\n",
    "\n",
    "        for i, data in enumerate(batch):\n",
    "            img_path = f\"{self.directory}/{data['name']}\"\n",
    "            image = load_img(img_path, target_size=self.target_size)\n",
    "            # image = img_to_array(image) / 255.0  \n",
    "            image = img_to_array(image)  \n",
    "\n",
    "            if self.augment:\n",
    "                image = self.image_data_generator.random_transform(image)\n",
    "            \n",
    "            X1[i, ] = image\n",
    "            X2[i, ] = data[self.label_list[0]]\n",
    "            y[i, ] = data[self.label_list[1:]]\n",
    "\n",
    "        return [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8281f-295c-4b67-b2bf-6399afcf5a59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "target_size = (256, 256)\n",
    "\n",
    "train_generator = CustomDataGenerator(train_csv, './train', batch_size, target_size, label_list, shuffle=False)\n",
    "test_generator = CustomDataGenerator(test_csv, './test', batch_size, target_size, label_list, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4849d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name() \n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')  \n",
    "for device in physical_devices:  \n",
    "     print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c195ed-b244-4498-bbe3-f7497f6ebf2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "y_train = []\n",
    "\n",
    "for i in tqdm(range(len(train_generator))):\n",
    "    batch_data, batch_labels = train_generator[i]\n",
    "    y_train.append(batch_labels)\n",
    "\n",
    "y_train = np.concatenate(y_train)\n",
    "y_test = []\n",
    "\n",
    "for i in tqdm(range(len(test_generator))):\n",
    "    batch_data, batch_labels = test_generator[i]\n",
    "    y_test.append(batch_labels)\n",
    "\n",
    "y_test = np.concatenate(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94889cc-616d-43da-96d1-96d36e820ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_model_history(model_history,model_name):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(12,4),dpi=120)\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['mse'])+1),model_history.history['mse'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_mse'])+1),model_history.history['val_mse'])\n",
    "    axs[0].set_title('Model mse')\n",
    "    axs[0].set_ylabel('mse')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    # axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
    "    # axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    # axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    fig.savefig(model_name+'_loss.jpg',dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c6214-052e-4a89-bfb6-297ed7faa6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    input_image = Input(shape=(224, 224, 3))\n",
    "    input_features = Input(shape=(1,))\n",
    "\n",
    "    base_model = tf.keras.applications.vgg16.VGG16(\n",
    "        weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling='avg'\n",
    "    )\n",
    "\n",
    "    from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "    x_in = tf.keras.layers.Lambda(preprocess_input)(input_image)\n",
    "    x = base_model(x_in)                 # [batch, 512]\n",
    "    x = Concatenate()([x, input_features])\n",
    "\n",
    "    activations = ['relu', 'tanh', 'relu']\n",
    "    for i, act in enumerate(activations):\n",
    "        units = hp.Int(f'units_{i}', min_value=64, max_value=512, step=64)\n",
    "        x = Dense(units=units, activation=act)(x)\n",
    "\n",
    "    output = Dense(5)(x)\n",
    "    model = Model(inputs=[input_image, input_features], outputs=output)\n",
    "    lr = hp.Float('lr', min_value=3e-5, max_value=1e-3, sampling='LOG')\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='vgg16_tuning'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(train_generator, epochs=10, validation_data=test_generator)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Learning rate: {best_hps.get('lr')}\")\n",
    "\n",
    "activations = ['relu', 'tanh', 'relu']\n",
    "for i, act in enumerate(activations):\n",
    "    print(f\"Layer {i+1}: units={best_hps.get(f'units_{i}')}, activation={act}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182b15c-958b-4110-92f1-cf1274f68fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(\"./model.ckpt\", monitor='val_loss', verbose=1,\n",
    "#                                                 save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=False\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79efd18-d40e-43e9-abd1-381cfc9bd6d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_info = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=100,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator),\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d76c4-de05-4f7a-866d-c81b8a691966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "joblib.dump(ss, 'scaler.pkl')  \n",
    "print(\"Model and scaler saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4977a-6374-4658-8a37-508afe4bf200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# loss_values = model_info.history['loss']\n",
    "# val_loss_values = model_info.history['val_loss']\n",
    "# df_loss = pd.DataFrame({'epoch': np.arange(1, num_epoch + 1), 'loss': loss_values, 'val_loss': val_loss_values})\n",
    "# df_loss.to_csv('loss_curve.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0d3e7-400f-4541-b8ba-bd96e8f6ee55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_model_history(model_info, 'Xception')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9335d55-6646-4d5c-9860-371f3f8bac59",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988666f0-e517-4a67-b2b2-27bb0843e2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# model.load_weights(\"./model.ckpt\")\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('./best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e4e272-068d-47b8-8550-fe1e6a9fbd4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_test_pred=model.predict(test_generator)\n",
    "y_train_pred=model.predict(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75155e68-5337-423b-98ae-552052974372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "y_test_pred=ss.inverse_transform(y_test_pred)\n",
    "y_test_true=ss.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ff935-5d92-4386-81ea-1cdada06704c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "y_train_pred=ss.inverse_transform(y_train_pred)\n",
    "y_train_true=ss.inverse_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149792c8-5dd4-4bc3-89ce-ed10a7402ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn import metrics\n",
    "def model_result(y_train,y_predict1,y_test,y_predict):\n",
    "    print('train_indexï¼š')\n",
    "    print('MSE: ', '%.4f'%float(mean_squared_error(y_train,y_predict1)),\\\n",
    "    'MAE: ', '%.4f'%float(mean_absolute_error(y_train,y_predict1)),\\\n",
    "    'RMSE:',' %.4f'%float(np.sqrt(mean_squared_error(y_train, y_predict1))),\\\n",
    "    'R2: ', '%.4f'%float(metrics.r2_score(y_train, y_predict1)))\n",
    "    \n",
    "    print('test_index')\n",
    "    print('MSE: ', '%.4f'%float(mean_squared_error(y_test,y_predict)),\\\n",
    "    'MAE: ', '%.4f'%float(mean_absolute_error(y_test,y_predict)),\\\n",
    "    'RMSE:', '%.4f'%float(np.sqrt(mean_squared_error(y_test, y_predict))),\\\n",
    "    'R2: ', '%.4f'%float(metrics.r2_score(y_test, y_predict)))\n",
    "    print('\\n')\n",
    "label_list2=['u', 'PCF', 'EA', 'SEA', 'k']\n",
    "for i in range(1,len(label_list2)+1):\n",
    "    print(label_list2[i-1])\n",
    "    model_result(y_train_true[:,i-1].ravel(),y_train_pred[:,i-1].ravel(),y_test_true[:,i-1].ravel(),y_test_pred[:,i-1].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f288ad-48f7-446a-affe-139dd84a7876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# matplotlib.rcParams['font.family']='SimHei''STSong'\n",
    "matplotlib.rcParams['axes.unicode_minus']=False\n",
    "color_list=['red','blue','purple','orange','yellow','green','pink','aquamarine','dodgerblue','purple','red','blue','orange','yellow','green']\n",
    "plt.figure(figsize=(12,10),dpi=120)\n",
    "for i in range(1,len(label_list2)+1):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.scatter(y_test_pred[:,i-1].ravel(),y_test_true[:,i-1].ravel(),color=color_list[i-1])\n",
    "    plt.title(label_list2[i-1])\n",
    "    plt.xlabel('Predict')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "plt.savefig('compaired.jpg',dpi=600,bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b7c751-33f6-4f65-8ad6-56f2c897448f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export trueâ€“predicted relationship data to Excel file\n",
    "with pd.ExcelWriter('true_vs_predicted_comparison.xlsx') as writer:\n",
    "    for i in range(1, 6):\n",
    "        df_comparison = pd.DataFrame({\n",
    "            'True_Value': y_test_true[:, i - 1].ravel(),\n",
    "            'Predicted_Value': y_test_pred[:, i - 1].ravel()\n",
    "        })\n",
    "        df_comparison.to_excel(writer, sheet_name=label_list2[i - 1], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
